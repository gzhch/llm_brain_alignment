{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/gzhch/miniconda3/envs/brain/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from typing import Dict\n",
    "import pickle\n",
    "import sklearn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/share/gzhch/resource/models/Llama-2-7b-hf/'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "exclude_files = dict(tunnel=['sub-004','sub-013'], lucy=['sub-053', 'sub-065'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(task_name):\n",
    "    with open('/data/gzhch/data/llm_act/{task_name}_1.pkl'.format(task_name=task_name), 'rb') as f:\n",
    "        llm_act = pickle.load(f)\n",
    "\n",
    "    with open('/data/gzhch/narratives/stimuli/gentle/{task_name}/align.json'.format(task_name=task_name), 'r') as f:\n",
    "        raw_input = json.loads(f.read())\n",
    "\n",
    "    with open('aligned_input.pkl', 'rb') as f:\n",
    "        all_aligned_inputs = pickle.load(f)\n",
    "        \n",
    "    input_ids = tokenizer(raw_input['transcript'])['input_ids']\n",
    "    \n",
    "    fmri_files = []\n",
    "    fmri_imgs = []\n",
    "    \n",
    "    folder_path = '/data/gzhch/narratives/derivatives/afni-nosmooth/'\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('nii.gz') and f'{task_name}' in filename:\n",
    "                participant = filename.split('_')[0]\n",
    "                if participant in exclude_files[task_name]:\n",
    "                    continue\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "                fmri_files.append(file_path)\n",
    "    fmri_files.sort()\n",
    "\n",
    "    for i, f in enumerate(fmri_files):\n",
    "        fmri_imgs.append(nib.load(f))\n",
    "    #     print(fmri_files[i].split('/')[-3], fmri_imgs[-1].shape)\n",
    "\n",
    "    return dict(llm_act=llm_act, input_aligned=all_aligned_inputs[task_name], input_ids=input_ids, fmri_imgs=fmri_imgs, fmri_files=fmri_files)\n",
    "\n",
    "def get_fdata(data):\n",
    "    data['fmri_act'] = [img.get_fdata() for img in data['fmri_imgs']]\n",
    "    return data\n",
    "\n",
    "def tr_alignment(data):\n",
    "    tr = 1.5\n",
    "    for i in range(len(data['input_aligned'])):\n",
    "        t = data['input_aligned'][-1-i]\n",
    "        if t['start'] < t['end']:\n",
    "            max_tr = math.ceil(t['end'] / tr)\n",
    "            break\n",
    "\n",
    "    tr_words = [[] for _ in range(max_tr)]\n",
    "    for c, w in enumerate(data['input_aligned']):\n",
    "        a = math.floor(w['start'] / tr)\n",
    "        b = math.ceil(w['end'] / tr)\n",
    "        l, r = w['word_to_token']\n",
    "        for i in range(a, b):\n",
    "            tr_words[i].append(c)\n",
    "\n",
    "    for i in range(len(tr_words)):\n",
    "        if tr_words[i] == []:\n",
    "            tr_words[i].append(tr_words[i-1][-1])\n",
    "\n",
    "    data['tr_to_words'] = tr_words\n",
    "    return data\n",
    "\n",
    "def reshape_llm_act(data):\n",
    "    tr_words = data['tr_to_words']\n",
    "    data['tr_to_ids'] = []\n",
    "    for words in tr_words:\n",
    "        l = data['input_aligned'][words[0]]['word_to_token'][0]\n",
    "        r = data['input_aligned'][words[-1]]['word_to_token'][1]\n",
    "        ids = list(range(l, r))\n",
    "        data['tr_to_ids'].append(ids)\n",
    "    return data\n",
    "\n",
    "def get_filtered_neurons(data, th=1, layer=12):\n",
    "    act_indices = torch.unbind(data['llm_act']['indices'][layer])\n",
    "    act_values = torch.unbind(data['llm_act']['values'][layer])\n",
    "    filtered_neurons = [i[v > th].tolist() for v, i in zip(act_values, act_indices)]\n",
    "    return filtered_neurons\n",
    "\n",
    "def diff(a, b):\n",
    "    if type(a) is not torch.Tensor:\n",
    "        a = torch.tensor(a)\n",
    "        b = torch.tensor(b)\n",
    "    return (a-b).norm().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lucy = load_data('lucy')\n",
    "data_tunnel = load_data('tunnel')\n",
    "\n",
    "data_lucy = tr_alignment(data_lucy)\n",
    "data_tunnel = tr_alignment(data_tunnel)\n",
    "\n",
    "data_lucy = reshape_llm_act(data_lucy)\n",
    "data_tunnel = reshape_llm_act(data_tunnel)\n",
    "\n",
    "data_lucy = get_fdata(data_lucy)\n",
    "data_tunnel = get_fdata(data_tunnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_indices = data_lucy['llm_act']['indices']\n",
    "act_values = data_lucy['llm_act']['values']\n",
    "act_shape = act_indices.shape\n",
    "# act_values = view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = 1 \n",
    "layer = 10\n",
    "act_indices = torch.unbind(data_lucy['llm_act']['indices'][layer])\n",
    "act_values = torch.unbind(data_lucy['llm_act']['values'][layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = get_filtered_neurons(data_lucy, th=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lucy['tr_to_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_llm_neurons = []\n",
    "for t in data_lucy['tr_to_ids']:\n",
    "    neurons = []\n",
    "    for i in t:\n",
    "        neurons += filtered[i]\n",
    "    neurons = set(neurons)\n",
    "    tr_llm_neurons.append(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([350, 350])\n"
     ]
    }
   ],
   "source": [
    "def set_diff(a, b):\n",
    "    return len(a & b) / len(a | b)\n",
    "\n",
    "llm_sim = []\n",
    "for i in range(len(tr_llm_neurons)):\n",
    "    row_sim = []\n",
    "    for j in range(len(tr_llm_neurons)):\n",
    "        row_sim.append(set_diff(tr_llm_neurons[i], tr_llm_neurons[j]))\n",
    "    llm_sim.append(row_sim)\n",
    "\n",
    "llm_sim = torch.tensor(llm_sim)\n",
    "print(llm_sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0794)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_sim.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0692, dtype=torch.float64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_sim.abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([370, 370])\n"
     ]
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.5144, dtype=torch.float64) tensor(-0.0311, dtype=torch.float64) tensor(0.0497, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "offset = 6\n",
    "t = brain_sim[offset: offset + llm_sim.shape[0], offset: offset + llm_sim.shape[1]]\n",
    "print((t-llm_sim).norm(), (t-llm_sim).mean(), (t-llm_sim).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offset:6 tensor(31.7056, dtype=torch.float64) tensor(0.0762, dtype=torch.float64) tensor(0.0719, dtype=torch.float64)\n",
      "offset:6 tensor(32.5146, dtype=torch.float64) tensor(0.0788, dtype=torch.float64) tensor(0.0641, dtype=torch.float64)\n",
      "offset:6 tensor(34.1406, dtype=torch.float64) tensor(0.0847, dtype=torch.float64) tensor(0.0547, dtype=torch.float64)\n",
      "offset:6 tensor(34.5137, dtype=torch.float64) tensor(0.0861, dtype=torch.float64) tensor(0.0544, dtype=torch.float64)\n",
      "offset:6 tensor(36.3580, dtype=torch.float64) tensor(0.0928, dtype=torch.float64) tensor(0.0491, dtype=torch.float64)\n",
      "offset:6 tensor(31.1921, dtype=torch.float64) tensor(0.0748, dtype=torch.float64) tensor(0.0666, dtype=torch.float64)\n",
      "offset:6 tensor(37.1414, dtype=torch.float64) tensor(0.0953, dtype=torch.float64) tensor(0.0491, dtype=torch.float64)\n",
      "offset:6 tensor(33.5578, dtype=torch.float64) tensor(0.0831, dtype=torch.float64) tensor(0.0582, dtype=torch.float64)\n",
      "offset:6 tensor(34.7900, dtype=torch.float64) tensor(0.0881, dtype=torch.float64) tensor(0.0522, dtype=torch.float64)\n",
      "offset:6 tensor(32.6499, dtype=torch.float64) tensor(0.0799, dtype=torch.float64) tensor(0.0661, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for sub in range(10):\n",
    "    t = torch.tensor(data_lucy['fmri_act'][sub])\n",
    "    max_tr = t.shape[-1]\n",
    "    t = t.reshape(-1, max_tr).transpose(0, 1)\n",
    "\n",
    "    brain_sim = torch.corrcoef(t).abs()\n",
    "    for offset in range(6,7):\n",
    "        t = brain_sim[offset: offset + llm_sim.shape[0], offset: offset + llm_sim.shape[1]]\n",
    "        print(f'offset:{offset}', (t-llm_sim).norm(), (t-llm_sim).abs().mean(), (t-llm_sim).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offset:6 tensor(35.7530, dtype=torch.float64) tensor(0.0909, dtype=torch.float64) tensor(0.0513, dtype=torch.float64)\n",
      "offset:6 tensor(37.3162, dtype=torch.float64) tensor(0.0961, dtype=torch.float64) tensor(0.0482, dtype=torch.float64)\n",
      "offset:6 tensor(35.4993, dtype=torch.float64) tensor(0.0895, dtype=torch.float64) tensor(0.0528, dtype=torch.float64)\n",
      "offset:6 tensor(35.7427, dtype=torch.float64) tensor(0.0903, dtype=torch.float64) tensor(0.0554, dtype=torch.float64)\n",
      "offset:6 tensor(31.6582, dtype=torch.float64) tensor(0.0762, dtype=torch.float64) tensor(0.0693, dtype=torch.float64)\n",
      "offset:6 tensor(33.9467, dtype=torch.float64) tensor(0.0847, dtype=torch.float64) tensor(0.0572, dtype=torch.float64)\n",
      "offset:6 tensor(34.9147, dtype=torch.float64) tensor(0.0880, dtype=torch.float64) tensor(0.0531, dtype=torch.float64)\n",
      "offset:6 tensor(33.2596, dtype=torch.float64) tensor(0.0821, dtype=torch.float64) tensor(0.0593, dtype=torch.float64)\n",
      "offset:6 tensor(36.4222, dtype=torch.float64) tensor(0.0931, dtype=torch.float64) tensor(0.0499, dtype=torch.float64)\n",
      "offset:6 tensor(31.0009, dtype=torch.float64) tensor(0.0743, dtype=torch.float64) tensor(0.0708, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for sub in range(10):\n",
    "    t = torch.tensor(data_tunnel['fmri_act'][sub])\n",
    "    max_tr = t.shape[-1]\n",
    "    t = t.reshape(-1, max_tr).transpose(0, 1)\n",
    "\n",
    "    brain_sim = torch.corrcoef(t).abs()\n",
    "    for offset in range(6,7):\n",
    "        t = brain_sim[offset: offset + llm_sim.shape[0], offset: offset + llm_sim.shape[1]]\n",
    "        print(f'offset:{offset}', (t-llm_sim).norm(), (t-llm_sim).abs().mean(), (t-llm_sim).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "## recover llm matrix\n",
    "def get_filtered_neurons(data, th=1, layer=12):\n",
    "    act_indices = torch.unbind(data['llm_act']['indices'][layer])\n",
    "    act_values = torch.unbind(data['llm_act']['values'][layer])\n",
    "    filtered_neurons = [i[v > th].tolist() for v, i in zip(act_values, act_indices)]\n",
    "    return filtered_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.unbind(data_lucy['llm_act']['indices'][16])\n",
    "values = torch.unbind(data_lucy['llm_act']['values'][16])\n",
    "ffn_gate = torch.unbind(torch.zeros(2271, 11008).half())\n",
    "for i in range(len(indices)):\n",
    "    ffn_gate[i][indices[i].to(torch.int)] = values[i]\n",
    "ffn_gate = torch.stack(ffn_gate)\n",
    "tr_words = data_lucy['tr_to_words']\n",
    "tr_llm_act = []\n",
    "for words in tr_words:\n",
    "    l = data_lucy['input_aligned'][words[0]]['word_to_token'][0]\n",
    "    r = data_lucy['input_aligned'][words[-1]]['word_to_token'][1]\n",
    "    ids = list(range(l, r))\n",
    "    tr_llm_act.append(ffn_gate[ids].sum(dim=0))\n",
    "tr_llm_act = torch.stack(tr_llm_act).float()\n",
    "tr_llm_act_low_rank, s, _ = torch.pca_lowrank(tr_llm_act, q=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 0\n",
    "tr_brain_act = torch.tensor(data_lucy['fmri_act'][sub])\n",
    "max_tr = tr_brain_act.shape[-1]\n",
    "tr_brain_act = tr_brain_act.reshape(-1, max_tr).transpose(0, 1)\n",
    "tr_brain_act_low_rank, _, _ = torch.pca_lowrank(tr_brain_act, q=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0396, -0.0143, -0.0514,  ..., -0.0005, -0.0624,  0.0025],\n",
       "        [ 0.0062,  0.0307,  0.0071,  ..., -0.0205, -0.1000,  0.0121],\n",
       "        [ 0.0265,  0.0026, -0.0122,  ...,  0.0098,  0.0123, -0.0214],\n",
       "        ...,\n",
       "        [ 0.0104,  0.0298,  0.0404,  ...,  0.0144,  0.0441,  0.0580],\n",
       "        [ 0.0220, -0.0206,  0.0632,  ..., -0.0496, -0.0072,  0.0311],\n",
       "        [-0.0032, -0.0542,  0.0024,  ...,  0.0008,  0.0153, -0.0453]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_brain_act_low_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([370, 6])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_brain_act_low_rank.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29443128965352455 -0.07294517128063545\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "offset = 8\n",
    "n_train = 270\n",
    "n_eval = 30\n",
    "x_train = tr_llm_act_low_rank[:n_train].numpy()\n",
    "x_eval = tr_llm_act_low_rank[n_train:n_train+n_eval].numpy()\n",
    "y_train = tr_brain_act_low_rank[offset:offset+n_train].numpy()\n",
    "y_eval = tr_brain_act_low_rank[offset+n_train:offset+n_train+n_eval].numpy()\n",
    "\n",
    "\n",
    "clf = Ridge(alpha=1)\n",
    "clf.fit(x_train, y_train)\n",
    "print(clf.score(x_train, y_train), clf.score(x_eval, y_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04338313383884836"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_eval, y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_zero = torch.zeros(torch.tensor(y_eval).shape).numpy()\n",
    "clf.score(x_eval, y_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29405949881305987"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.19521765e-02, -6.95774257e-02, -1.03463326e-03,\n",
       "        -2.44314522e-02,  1.58921684e-04, -3.22564654e-02],\n",
       "       [-1.96992811e-02, -3.89579713e-04,  3.17841321e-02,\n",
       "         6.31387811e-03,  9.23208706e-03, -3.31459269e-02],\n",
       "       [ 5.14575541e-02,  9.25030001e-03,  6.08093552e-02,\n",
       "         1.58198476e-02, -3.20081599e-03,  1.17002381e-02],\n",
       "       [-1.81398459e-03,  7.36554805e-03,  3.48787047e-02,\n",
       "         1.85895395e-02,  4.72770929e-02,  3.96052785e-02],\n",
       "       [-8.09315871e-03, -3.89149189e-02, -2.39572320e-02,\n",
       "        -3.43334451e-02,  6.89699948e-02,  2.32156254e-02],\n",
       "       [-2.87540518e-02, -4.17115241e-02,  7.82132335e-03,\n",
       "         4.75939084e-03, -9.60046527e-05,  7.54610375e-02],\n",
       "       [ 5.60508221e-02, -7.56961331e-02, -4.41426560e-02,\n",
       "         1.54635543e-02, -4.89861593e-02,  1.47646382e-01],\n",
       "       [-6.93465164e-03, -3.93947251e-02,  2.20387429e-02,\n",
       "         7.13125942e-03, -3.15610059e-02,  8.37234482e-02],\n",
       "       [-5.10896966e-02, -5.21181375e-02,  1.23415245e-02,\n",
       "        -4.93430393e-03, -2.82668062e-02,  4.77377623e-02],\n",
       "       [-3.86803448e-02, -1.06687695e-01, -4.00372688e-03,\n",
       "        -9.90345259e-04, -6.61539137e-02,  7.22150207e-02],\n",
       "       [-3.01799830e-02, -1.16632313e-01, -1.07096414e-04,\n",
       "        -1.62542388e-02, -5.40474020e-02,  6.80017099e-02],\n",
       "       [ 6.60588546e-03, -1.03054538e-01, -8.23406223e-03,\n",
       "         1.69810711e-03, -3.51376720e-02,  1.30031541e-01],\n",
       "       [-2.38594823e-02, -8.51385742e-02, -1.49754155e-02,\n",
       "        -9.64144431e-03, -1.81034505e-02,  6.00133203e-02],\n",
       "       [-4.14725579e-02, -6.21870644e-02, -1.73913743e-02,\n",
       "         6.94323750e-03, -1.50582595e-02,  5.39838597e-02],\n",
       "       [-6.37256727e-02, -8.69867504e-02,  1.57149378e-02,\n",
       "        -1.34814391e-03, -3.67099456e-02, -3.92830418e-03],\n",
       "       [-4.22511920e-02, -5.83257675e-02,  1.56374238e-02,\n",
       "         4.72535659e-03, -3.90290376e-03,  1.46546345e-02],\n",
       "       [ 3.38390581e-02,  5.46593927e-02,  1.64728370e-02,\n",
       "         1.63470171e-02,  1.17359012e-02, -2.79567260e-02],\n",
       "       [ 1.40430748e-01,  9.54767913e-02, -1.30277872e-03,\n",
       "         1.51195489e-02,  1.76504683e-02, -7.56434426e-02],\n",
       "       [ 6.55198917e-02,  6.89515173e-02,  1.80504229e-02,\n",
       "        -2.57766433e-02,  1.37849189e-02, -3.47134247e-02],\n",
       "       [-4.42274101e-02,  6.33602440e-02, -8.64380877e-03,\n",
       "        -2.60989368e-02,  1.03549026e-02, -2.25681327e-02],\n",
       "       [-7.50210956e-02,  5.65703548e-02, -4.61267075e-03,\n",
       "        -2.99084838e-02, -2.38597039e-02, -2.84882020e-02],\n",
       "       [-5.10766655e-02,  6.26645833e-02, -2.10434906e-02,\n",
       "        -7.86900297e-02, -5.59866838e-02, -3.53883579e-02],\n",
       "       [ 3.69845591e-02,  6.86118603e-02, -1.33665413e-01,\n",
       "        -2.72464901e-01, -1.64518714e-01, -8.39518458e-02],\n",
       "       [-3.76437679e-02,  5.48521504e-02, -3.30791548e-02,\n",
       "        -1.02176182e-01, -7.76716769e-02, -5.53103350e-02],\n",
       "       [-4.24778201e-02,  5.14098443e-02, -3.68262306e-02,\n",
       "        -1.03652976e-01, -6.89365640e-02, -5.02693132e-02],\n",
       "       [-3.57099660e-02,  5.09313568e-02, -1.96213797e-02,\n",
       "        -1.03457965e-01, -6.34599850e-02, -4.58854996e-02],\n",
       "       [-2.24163644e-02,  5.31416163e-02, -4.03969698e-02,\n",
       "        -1.45935759e-01, -8.20022076e-02, -4.82236631e-02],\n",
       "       [ 7.48082325e-02,  5.97147830e-02, -1.00860491e-01,\n",
       "        -2.98698336e-01, -1.01030104e-01, -3.43836136e-02],\n",
       "       [-6.61232471e-02,  5.20252325e-02,  5.18529769e-03,\n",
       "        -3.83321494e-02, -3.46686617e-02, -5.52846259e-03],\n",
       "       [ 3.16467397e-02,  3.86845134e-02, -7.36421272e-02,\n",
       "        -2.01362789e-01, -9.18095782e-02,  1.34732085e-03]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.790532093436896"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2730.3357) tensor(241.6544)\n",
      "tensor(2775.7405) tensor(388.1245)\n",
      "tensor(2756.1538) tensor(327.9261)\n"
     ]
    }
   ],
   "source": [
    "def inner_dis(acts, time1, time2):\n",
    "    l = len(acts)\n",
    "    dis = []\n",
    "    for i in range(l):\n",
    "        for j in range(i + 1, l):\n",
    "            dis.append(diff(acts[i][:, :, :, time1], acts[j][:, :, :, time2]))\n",
    "    dis = torch.tensor(dis)\n",
    "    print(dis.mean(), dis.std())\n",
    "\n",
    "def inter_dis(acts1, acts2, time1, time2):\n",
    "    dis = []\n",
    "    for a in acts1:\n",
    "        for b in acts2:\n",
    "            dis.append(diff(a[:, :, :, time1], b[:, :, :, time2]))\n",
    "    dis = torch.tensor(dis)\n",
    "    print(dis.mean(), dis.std())\n",
    "\n",
    "inner_dis(data_lucy['fmri_act'][:-1], 100, 100)\n",
    "inner_dis(data_tunnel['fmri_act'][:-1], 100, 100)\n",
    "inter_dis(data_lucy['fmri_act'][:-1], data_tunnel['fmri_act'][:-1], 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "tensor(2792.5964) tensor(408.9689)\n",
      "0 20\n",
      "tensor(2791.8516) tensor(391.3250)\n",
      "0 40\n",
      "tensor(2741.9087) tensor(395.5639)\n",
      "0 60\n",
      "tensor(2708.2378) tensor(399.6494)\n",
      "0 80\n",
      "tensor(2745.5054) tensor(450.3113)\n",
      "0 100\n",
      "tensor(2745.5635) tensor(388.7130)\n",
      "0 120\n",
      "tensor(2750.7163) tensor(386.6628)\n",
      "0 140\n",
      "tensor(2831.6277) tensor(394.7903)\n",
      "0 160\n",
      "tensor(2799.4453) tensor(383.5285)\n",
      "0 180\n",
      "tensor(2830.8284) tensor(383.8633)\n",
      "0 200\n",
      "tensor(2750.9917) tensor(389.5215)\n",
      "0 220\n",
      "tensor(2842.1714) tensor(428.9813)\n",
      "0 240\n",
      "tensor(2793.2007) tensor(413.5020)\n",
      "0 260\n",
      "tensor(2749.4810) tensor(406.9154)\n",
      "0 280\n",
      "tensor(2764.4436) tensor(390.7912)\n",
      "0 300\n",
      "tensor(2817.4138) tensor(394.3676)\n",
      "0 320\n",
      "tensor(2829.8596) tensor(412.8351)\n",
      "0 340\n",
      "tensor(2794.2546) tensor(417.4810)\n",
      "0 360\n",
      "tensor(2763.5847) tensor(382.2531)\n",
      "20 20\n",
      "tensor(2769.5854) tensor(265.7102)\n",
      "20 40\n",
      "tensor(2736.1877) tensor(277.1757)\n",
      "20 60\n",
      "tensor(2693.0085) tensor(270.8752)\n",
      "20 80\n",
      "tensor(2732.4910) tensor(341.8155)\n",
      "20 100\n",
      "tensor(2733.6453) tensor(261.7294)\n",
      "20 120\n",
      "tensor(2737.5525) tensor(262.7502)\n",
      "20 140\n",
      "tensor(2818.7747) tensor(287.8774)\n",
      "20 160\n",
      "tensor(2785.7280) tensor(258.8487)\n",
      "20 180\n",
      "tensor(2812.6926) tensor(252.0163)\n",
      "20 200\n",
      "tensor(2737.6760) tensor(262.0313)\n",
      "20 220\n",
      "tensor(2829.8257) tensor(324.7454)\n",
      "20 240\n",
      "tensor(2782.1628) tensor(304.9485)\n",
      "20 260\n",
      "tensor(2737.7710) tensor(287.8600)\n",
      "20 280\n",
      "tensor(2748.4849) tensor(265.5052)\n",
      "20 300\n",
      "tensor(2804.5349) tensor(276.6259)\n",
      "20 320\n",
      "tensor(2822.2986) tensor(308.6268)\n",
      "20 340\n",
      "tensor(2780.1863) tensor(302.6046)\n",
      "20 360\n",
      "tensor(2756.9568) tensor(255.5913)\n",
      "40 40\n",
      "tensor(2750.8799) tensor(295.7050)\n",
      "40 60\n",
      "tensor(2707.8379) tensor(289.6393)\n",
      "40 80\n",
      "tensor(2749.2317) tensor(367.1126)\n",
      "40 100\n",
      "tensor(2749.1616) tensor(284.6190)\n",
      "40 120\n",
      "tensor(2756.4771) tensor(278.5815)\n",
      "40 140\n",
      "tensor(2836.9407) tensor(311.3310)\n",
      "40 160\n",
      "tensor(2796.7117) tensor(272.6558)\n",
      "40 180\n",
      "tensor(2828.0295) tensor(277.6368)\n",
      "40 200\n",
      "tensor(2752.9695) tensor(284.0095)\n",
      "40 220\n",
      "tensor(2842.6919) tensor(338.1338)\n",
      "40 240\n",
      "tensor(2801.1206) tensor(322.8111)\n",
      "40 260\n",
      "tensor(2753.5750) tensor(308.5077)\n",
      "40 280\n",
      "tensor(2768.6021) tensor(289.1418)\n",
      "40 300\n",
      "tensor(2822.1614) tensor(291.9050)\n",
      "40 320\n",
      "tensor(2831.8354) tensor(318.9785)\n",
      "40 340\n",
      "tensor(2799.1594) tensor(324.9338)\n",
      "40 360\n",
      "tensor(2774.9485) tensor(273.8846)\n",
      "60 60\n",
      "tensor(2630.8157) tensor(254.7330)\n",
      "60 80\n",
      "tensor(2667.4663) tensor(339.3766)\n",
      "60 100\n",
      "tensor(2668.3459) tensor(251.8172)\n",
      "60 120\n",
      "tensor(2679.8083) tensor(249.2792)\n",
      "60 140\n",
      "tensor(2757.0889) tensor(287.5296)\n",
      "60 160\n",
      "tensor(2721.0835) tensor(245.1694)\n",
      "60 180\n",
      "tensor(2755.9951) tensor(246.2618)\n",
      "60 200\n",
      "tensor(2674.0361) tensor(252.4043)\n",
      "60 220\n",
      "tensor(2767.2844) tensor(318.2071)\n",
      "60 240\n",
      "tensor(2722.8147) tensor(299.4594)\n",
      "60 260\n",
      "tensor(2674.0566) tensor(278.7031)\n",
      "60 280\n",
      "tensor(2692.4517) tensor(260.6245)\n",
      "60 300\n",
      "tensor(2745.2322) tensor(271.0074)\n",
      "60 320\n",
      "tensor(2758.9204) tensor(300.1286)\n",
      "60 340\n",
      "tensor(2722.4961) tensor(301.0870)\n",
      "60 360\n",
      "tensor(2697.2739) tensor(240.1242)\n",
      "80 80\n",
      "tensor(2742.1074) tensor(402.2561)\n",
      "80 100\n",
      "tensor(2750.2651) tensor(332.9124)\n",
      "80 120\n",
      "tensor(2756.4429) tensor(325.2019)\n",
      "80 140\n",
      "tensor(2836.4973) tensor(361.6408)\n",
      "80 160\n",
      "tensor(2803.0947) tensor(326.1973)\n",
      "80 180\n",
      "tensor(2826.2236) tensor(329.1952)\n",
      "80 200\n",
      "tensor(2754.4282) tensor(336.1592)\n",
      "80 220\n",
      "tensor(2842.5645) tensor(384.0453)\n",
      "80 240\n",
      "tensor(2800.5361) tensor(364.1588)\n",
      "80 260\n",
      "tensor(2746.4824) tensor(355.9773)\n",
      "80 280\n",
      "tensor(2767.8511) tensor(340.6109)\n",
      "80 300\n",
      "tensor(2823.0957) tensor(346.7852)\n",
      "80 320\n",
      "tensor(2834.4502) tensor(367.7918)\n",
      "80 340\n",
      "tensor(2795.8318) tensor(363.0609)\n",
      "80 360\n",
      "tensor(2777.4136) tensor(324.3736)\n",
      "100 100\n",
      "tensor(2730.3357) tensor(241.6544)\n",
      "100 120\n",
      "tensor(2742.7747) tensor(237.9598)\n",
      "100 140\n",
      "tensor(2813.6052) tensor(277.3727)\n",
      "100 160\n",
      "tensor(2785.7720) tensor(235.1752)\n",
      "100 180\n",
      "tensor(2813.6621) tensor(238.3268)\n",
      "100 200\n",
      "tensor(2735.4717) tensor(246.6673)\n",
      "100 220\n",
      "tensor(2830.6787) tensor(310.5119)\n",
      "100 240\n",
      "tensor(2782.2629) tensor(289.0136)\n",
      "100 260\n",
      "tensor(2744.5625) tensor(276.3449)\n",
      "100 280\n",
      "tensor(2757.7734) tensor(256.0990)\n",
      "100 300\n",
      "tensor(2806.6697) tensor(265.4285)\n",
      "100 320\n",
      "tensor(2816.0681) tensor(286.9971)\n",
      "100 340\n",
      "tensor(2783.6948) tensor(292.9234)\n",
      "100 360\n",
      "tensor(2757.8843) tensor(233.3934)\n",
      "120 120\n",
      "tensor(2792.2854) tensor(306.2421)\n",
      "120 140\n",
      "tensor(2869.4800) tensor(329.2422)\n",
      "120 160\n",
      "tensor(2836.2097) tensor(296.6605)\n",
      "120 180\n",
      "tensor(2866.0713) tensor(297.2323)\n",
      "120 200\n",
      "tensor(2789.2937) tensor(309.2025)\n",
      "120 220\n",
      "tensor(2878.1267) tensor(354.5035)\n",
      "120 240\n",
      "tensor(2834.3760) tensor(345.3079)\n",
      "120 260\n",
      "tensor(2788.2373) tensor(336.0357)\n",
      "120 280\n",
      "tensor(2804.8862) tensor(312.7682)\n",
      "120 300\n",
      "tensor(2857.0530) tensor(314.0755)\n",
      "120 320\n",
      "tensor(2872.4871) tensor(342.6837)\n",
      "120 340\n",
      "tensor(2835.1855) tensor(349.4826)\n",
      "120 360\n",
      "tensor(2809.8206) tensor(301.2546)\n",
      "140 140\n",
      "tensor(2862.0581) tensor(318.5163)\n",
      "140 160\n",
      "tensor(2835.1294) tensor(297.8848)\n",
      "140 180\n",
      "tensor(2860.9465) tensor(300.7454)\n",
      "140 200\n",
      "tensor(2786.9480) tensor(298.7216)\n",
      "140 220\n",
      "tensor(2877.9094) tensor(358.0051)\n",
      "140 240\n",
      "tensor(2832.4854) tensor(343.8401)\n",
      "140 260\n",
      "tensor(2795.4702) tensor(332.4778)\n",
      "140 280\n",
      "tensor(2805.2573) tensor(308.0169)\n",
      "140 300\n",
      "tensor(2856.8359) tensor(323.5251)\n",
      "140 320\n",
      "tensor(2867.4221) tensor(346.4109)\n",
      "140 340\n",
      "tensor(2834.6670) tensor(341.8364)\n",
      "140 360\n",
      "tensor(2803.7480) tensor(297.2968)\n",
      "160 160\n",
      "tensor(2801.4822) tensor(254.5574)\n",
      "160 180\n",
      "tensor(2831.9895) tensor(265.8696)\n",
      "160 200\n",
      "tensor(2754.8672) tensor(270.9707)\n",
      "160 220\n",
      "tensor(2846.9800) tensor(328.3427)\n",
      "160 240\n",
      "tensor(2799.3486) tensor(313.9806)\n",
      "160 260\n",
      "tensor(2758.5073) tensor(296.1170)\n",
      "160 280\n",
      "tensor(2772.1375) tensor(276.7614)\n",
      "160 300\n",
      "tensor(2819.7646) tensor(284.4503)\n",
      "160 320\n",
      "tensor(2837.9631) tensor(308.6151)\n",
      "160 340\n",
      "tensor(2800.9841) tensor(315.7438)\n",
      "160 360\n",
      "tensor(2775.0251) tensor(261.2025)\n",
      "180 180\n",
      "tensor(2905.0588) tensor(322.7071)\n",
      "180 200\n",
      "tensor(2827.3123) tensor(330.1755)\n",
      "180 220\n",
      "tensor(2918.5640) tensor(378.7029)\n",
      "180 240\n",
      "tensor(2871.0242) tensor(350.3064)\n",
      "180 260\n",
      "tensor(2825.9082) tensor(345.4427)\n",
      "180 280\n",
      "tensor(2842.7400) tensor(332.0879)\n",
      "180 300\n",
      "tensor(2893.7144) tensor(330.5467)\n",
      "180 320\n",
      "tensor(2905.8479) tensor(356.6729)\n",
      "180 340\n",
      "tensor(2870.8411) tensor(356.5344)\n",
      "180 360\n",
      "tensor(2848.7075) tensor(320.7781)\n",
      "200 200\n",
      "tensor(2782.4434) tensor(281.1657)\n",
      "200 220\n",
      "tensor(2878.8308) tensor(341.7498)\n",
      "200 240\n",
      "tensor(2831.5100) tensor(321.9634)\n",
      "200 260\n",
      "tensor(2789.1150) tensor(314.9335)\n",
      "200 280\n",
      "tensor(2800.1699) tensor(291.8421)\n",
      "200 300\n",
      "tensor(2849.9102) tensor(292.8825)\n",
      "200 320\n",
      "tensor(2870.0005) tensor(322.6918)\n",
      "200 340\n",
      "tensor(2830.8164) tensor(323.4020)\n",
      "200 360\n",
      "tensor(2806.7659) tensor(278.9118)\n",
      "220 220\n",
      "tensor(2947.3667) tensor(367.7609)\n",
      "220 240\n",
      "tensor(2899.5752) tensor(360.8271)\n",
      "220 260\n",
      "tensor(2855.5122) tensor(349.2155)\n",
      "220 280\n",
      "tensor(2875.0188) tensor(337.2992)\n",
      "220 300\n",
      "tensor(2927.0935) tensor(339.4464)\n",
      "220 320\n",
      "tensor(2935.0234) tensor(354.9709)\n",
      "220 340\n",
      "tensor(2899.8850) tensor(363.1964)\n",
      "220 360\n",
      "tensor(2872.6748) tensor(320.8967)\n",
      "240 240\n",
      "tensor(2798.0496) tensor(308.3397)\n",
      "240 260\n",
      "tensor(2752.2058) tensor(292.5979)\n",
      "240 280\n",
      "tensor(2766.4963) tensor(272.0730)\n",
      "240 300\n",
      "tensor(2819.9238) tensor(284.2783)\n",
      "240 320\n",
      "tensor(2832.0266) tensor(306.1555)\n",
      "240 340\n",
      "tensor(2798.3081) tensor(305.4864)\n",
      "240 360\n",
      "tensor(2774.4919) tensor(263.3942)\n",
      "260 260\n",
      "tensor(2866.2166) tensor(414.0143)\n",
      "260 280\n",
      "tensor(2886.2644) tensor(397.6531)\n",
      "260 300\n",
      "tensor(2939.5698) tensor(396.5392)\n",
      "260 320\n",
      "tensor(2949.7610) tensor(409.4314)\n",
      "260 340\n",
      "tensor(2915.7109) tensor(419.2395)\n",
      "260 360\n",
      "tensor(2890.2405) tensor(390.3075)\n",
      "280 280\n",
      "tensor(2805.2776) tensor(304.4931)\n",
      "280 300\n",
      "tensor(2857.9028) tensor(310.2645)\n",
      "280 320\n",
      "tensor(2871.9089) tensor(330.9317)\n",
      "280 340\n",
      "tensor(2834.0100) tensor(329.6180)\n",
      "280 360\n",
      "tensor(2811.9482) tensor(294.2591)\n",
      "300 300\n",
      "tensor(2861.3828) tensor(291.4071)\n",
      "300 320\n",
      "tensor(2871.6775) tensor(319.4697)\n",
      "300 340\n",
      "tensor(2839.5691) tensor(322.2542)\n",
      "300 360\n",
      "tensor(2809.6526) tensor(278.6161)\n",
      "320 320\n",
      "tensor(2976.5151) tensor(474.2730)\n",
      "320 340\n",
      "tensor(2941.2358) tensor(480.9604)\n",
      "320 360\n",
      "tensor(2917.5059) tensor(461.6458)\n",
      "340 340\n",
      "tensor(2809.2922) tensor(317.7801)\n",
      "340 360\n",
      "tensor(2787.1995) tensor(276.7607)\n",
      "360 360\n",
      "tensor(2867.6191) tensor(334.3113)\n"
     ]
    }
   ],
   "source": [
    "max_time = data_lucy['fmri_act'][0].shape[-1]\n",
    "\n",
    "for t1 in range(0, max_time, 20):\n",
    "    for t2 in range(t1, max_time, 20):\n",
    "        print(t1, t2)\n",
    "        inner_dis(data_lucy['fmri_act'][:-1], t1, t2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (370) must match the size of tensor b (1040) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m i, j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_lucy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfmri_act\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_tunnel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfmri_act\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 42\u001b[0m, in \u001b[0;36mdiff\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     40\u001b[0m     a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(a)\n\u001b[1;32m     41\u001b[0m     b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(b)\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43ma\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mb\u001b[49m)\u001b[38;5;241m.\u001b[39mnorm()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (370) must match the size of tensor b (1040) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "i, j = 8, 9\n",
    "diff(data_lucy['fmri_act'][i], data_tunnel['fmri_act'][j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a) == torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
