{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0539e6f-4d83-4156-85f2-7373253b69d9",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T14:04:16.888006Z",
     "shell.execute_reply.started": "2024-01-27T14:04:16.350184Z",
     "to_execute": "2024-01-27T14:04:12.268Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "import random\n",
    "import scipy\n",
    "import config\n",
    "from GPT import GPT\n",
    "from LLAMA import LLAMA\n",
    "from StimulusModel import LMFeatures\n",
    "from utils_stim import get_story_wordseqs\n",
    "# from utils_resp import get_resp\n",
    "from utils_ridge.ridge import ridge, bootstrap_ridge, ridge_corr\n",
    "from utils_ridge.ridge_torch import ridge_torch, bootstrap_ridge_torch, ridge_corr_torch\n",
    "from utils_ridge.stimulus_utils import TRFile, load_textgrids, load_simulated_trfiles\n",
    "from utils_ridge.dsutils import make_word_ds\n",
    "from utils_ridge.interpdata import lanczosinterp2D, lanczosinterp2D_torch\n",
    "from utils_ridge.util import make_delayed\n",
    "from utils_ridge.utils import mult_diag, counter\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig, pipeline\n",
    "import utils_llama.activation as ana\n",
    "\n",
    "import scipy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "import datasets\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c02aa19-05ff-4ab3-a2e0-9ba1c01035e8",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T15:11:48.029739Z",
     "shell.execute_reply.started": "2024-01-27T15:11:47.443314Z",
     "to_execute": "2024-01-27T15:11:47.429Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f3c491eda30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a532e17e-9c91-49a1-aac1-6a0cf8da720d",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T15:11:49.123932Z",
     "shell.execute_reply.started": "2024-01-27T15:11:49.093685Z",
     "to_execute": "2024-01-27T15:11:49.074Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "# torch.cuda.memory._record_memory_history()\n",
    "class ARGS:\n",
    "    def __init__(self):\n",
    "        self.subject = 'S1'\n",
    "        self.gpt = 'perceived'\n",
    "        self.sessions = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 18, 20]\n",
    "        self.layer = 17\n",
    "        self.layer2 = 18\n",
    "        self.act_name = 'ffn_gate'\n",
    "        self.window = 15\n",
    "        self.chunk = 4\n",
    "\n",
    "args = ARGS()\n",
    "\n",
    "# # training stories\n",
    "# stories = []\n",
    "# with open(os.path.join(config.DATA_TRAIN_DIR, \"sess_to_story.json\"), \"r\") as f:\n",
    "#     sess_to_story = json.load(f) \n",
    "# for sess in args.sessions:\n",
    "#     stories.extend(sess_to_story[str(sess)])\n",
    "\n",
    "# stories = stories[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccb2043e-ffa1-4f87-8b0d-86cc987371a3",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T15:11:50.831130Z",
     "shell.execute_reply.started": "2024-01-27T15:11:50.435939Z",
     "to_execute": "2024-01-27T15:11:50.409Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "model_dir = '/ossfs/workspace/nas/gzhch/data/models/Llama-2-7b-hf'\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_dir, \n",
    "#     device_map='auto',\n",
    "#     torch_dtype=torch.float16,\n",
    "# ).eval()\n",
    "\n",
    "model = None\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12d3a0e0-bfbd-4ff6-a539-d0b5b632b45c",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T15:11:52.602293Z",
     "shell.execute_reply.started": "2024-01-27T15:11:52.577193Z",
     "to_execute": "2024-01-27T15:11:52.551Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "## load cached llm act if possible\n",
    "cache_dir = '/ossfs/workspace/nas/gzhch/data/cache'\n",
    "llama = LLAMA(model, tokenizer, cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bedaa010-a6a7-4d17-a5e6-ad6e6116168d",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T15:05:35.630737Z",
     "shell.execute_reply.started": "2024-01-27T15:05:35.602122Z",
     "to_execute": "2024-01-27T15:05:35.589Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "def load_data(task_name, n_shot=1, seed=42):\n",
    "    data_dirs = {\n",
    "        'xsum' : '/ossfs/workspace/nas/gzhch/data/datasets/xsum',\n",
    "        'gsm8k' : '/ossfs/workspace/nas/gzhch/data/datasets/gsm8k',\n",
    "        'alpaca' : '/ossfs/workspace/nas/gzhch/data/datasets/alpaca',\n",
    "        'wmt' : '/ossfs/workspace/nas/gzhch/data/datasets/wmt14_de-en_test',\n",
    "        'wikitext2' : '/ossfs/workspace/nas/gzhch/data/datasets/wikitext-2-v1'\n",
    "    }\n",
    "    if task_name == 'gsm8k':\n",
    "        dataset = datasets.load_dataset(data_dirs[task_name])\n",
    "    elif task_name == 'wikitext2':\n",
    "        dataset = datasets.load_from_disk(data_dirs[task_name])\n",
    "        dataset = dataset['train'].filter(lambda x: len(x['text'])>100) \n",
    "        dataset = dataset.select(random.sample(range(len(dataset)), 1000))\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4494bcdf-bec6-4c4f-ad43-5ee0230c316c",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T15:05:39.528136Z",
     "shell.execute_reply.started": "2024-01-27T15:05:36.423551Z",
     "to_execute": "2024-01-27T15:05:36.390Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "wiki_data = load_data('wikitext2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "796e3fd3-7a00-4000-8645-3d1d7f93dd68",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T10:49:48.932705Z",
     "shell.execute_reply.started": "2024-01-27T10:49:48.903603Z",
     "to_execute": "2024-01-27T10:49:44.767Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "def get_neuron_activation_and_loss(model, input):\n",
    "    result = ana.custom_forward(model, input['input_ids'].cuda(), inspect_acts=['ffn_gate'])\n",
    "    logits = result['logits']\n",
    "    labels = input['input_ids']\n",
    "    input_ids = input['input_ids'][:, :-1]\n",
    "\n",
    "    # calculate loss\n",
    "    shift_logits = logits[..., :-1, :].contiguous().view(-1, 32000)\n",
    "    shift_labels = labels[..., 1:].contiguous().view(-1)\n",
    "    loss_fct = torch.nn.CrossEntropyLoss(reduce=False)\n",
    "    loss = loss_fct(shift_logits, shift_labels).view(labels.shape[0], -1)\n",
    "\n",
    "    b = 5\n",
    "    mask = input['attention_mask'][:, :-1] == 1\n",
    "    loss = loss * mask + -100 * (~mask)\n",
    "    input_ids = input_ids * mask + -100 * (~mask)\n",
    "    expanded_loss = torch.cat([torch.ones(loss.shape[0], b) * -100, loss, torch.ones(loss.shape[0], b) * -100], dim=1)\n",
    "    expanded_input_ids = torch.cat([torch.ones(input_ids.shape[0], b) * -100, input_ids, torch.ones(input_ids.shape[0], b) * -100], dim=1).int()\n",
    "\n",
    "    # signal delay\n",
    "    losses = []\n",
    "    context = []\n",
    "    for offset in range(2 * b):\n",
    "        losses.append(expanded_loss[:, offset: offset + loss.shape[1]])\n",
    "        context.append(expanded_input_ids[:, offset: offset + loss.shape[1]])\n",
    "    losses = torch.stack(losses).transpose(0,1).transpose(2,1)\n",
    "    context = torch.stack(context).transpose(0,1).transpose(2,1)\n",
    "\n",
    "    ## remove padding tokens\n",
    "    losses = losses.view(-1, 2 * b)[mask.flatten()]\n",
    "    context = context.view(-1, 2 * b)[mask.flatten()]\n",
    "\n",
    "    ffn_gate_all_layer = torch.stack(result['ffn_gate'])[:, :, :-1, :]\n",
    "    l, bs, seq_len, h = ffn_gate_all_layer.shape\n",
    "    ffn_gate_all_layer = ffn_gate_all_layer.reshape(l, bs * seq_len, h).transpose(0, 1)\n",
    "    ffn_gate_all_layer = ffn_gate_all_layer[mask.flatten()]\n",
    "\n",
    "    res = dict(context=context, loss=losses, ffn_gate=ffn_gate_all_layer)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "96c26fcc-4d9e-45c4-86be-9f95d95db2a6",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-26T08:36:07.198587Z",
     "shell.execute_reply.started": "2024-01-26T08:35:16.548321Z",
     "to_execute": "2024-01-26T08:35:16.481Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "total_batch = len(wiki_data) // batch_size\n",
    "max_batch = 5\n",
    "acts = []\n",
    "for k in range(min(total_batch, max_batch)):\n",
    "    input = tokenizer(wiki_data['text'][k * batch_size: (k + 1) * batch_size], return_tensors='pt', padding='longest')\n",
    "    acts.append(get_neuron_activation_and_loss(model, input))\n",
    "\n",
    "context = torch.cat([i['context'] for i in acts], dim=0).numpy()\n",
    "loss = torch.cat([i['loss'] for i in acts], dim=0).numpy()\n",
    "ffn_gate = torch.cat([i['ffn_gate'] for i in acts], dim=0).numpy()\n",
    "\n",
    "cache_subdir = os.path.join(cache_dir, 'wiki', 'bs_16_0-5')\n",
    "if not os.path.exists(cache_subdir):\n",
    "    os.makedirs(cache_subdir, exist_ok=True)\n",
    "with open(os.path.join(cache_subdir, 'context.pickle'), 'wb') as f:\n",
    "    pickle.dump(context, f)\n",
    "with open(os.path.join(cache_subdir, 'loss.pickle'), 'wb') as f:\n",
    "    pickle.dump(loss, f)\n",
    "for layer in range(ffn_gate.shape[1]):\n",
    "    with open(os.path.join(cache_subdir, f'ffn_gate_{layer}.pickle'), 'wb') as f:\n",
    "        pickle.dump(ffn_gate[:, layer, :], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6a05be7-7cbb-4437-b2af-9f7ee1b53d13",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T15:13:33.995084Z",
     "shell.execute_reply.started": "2024-01-27T15:12:01.974735Z",
     "to_execute": "2024-01-27T15:12:01.957Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "actss = []\n",
    "for s in [0, 5, 10, 15, 20, 25]:\n",
    "    acts = llama.get_act(wiki_data, \n",
    "                        cache_name = 'wiki', \n",
    "                        layers = [10, 15],\n",
    "                        acts = {},\n",
    "                        start_batch=s, \n",
    "                        end_batch=s+5)\n",
    "    actss.append(acts)\n",
    "# print(acts.keys())\n",
    "stim_data = {}\n",
    "for k in actss[0].keys():\n",
    "    stim_data[k] = np.concatenate([i[k] for i in actss])\n",
    "del actss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32870eed-6481-417e-89b1-bf3ae8c75ad5",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T15:21:38.342621Z",
     "shell.execute_reply.started": "2024-01-27T15:21:27.596964Z",
     "to_execute": "2024-01-27T15:21:27.588Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-27 23:21:30,057 - ridge_corr - INFO - Selecting held-out test set..\n",
      "2024-01-27 23:21:30,121 - ridge_corr - INFO - Doing SVD...\n",
      "2024-01-27 23:21:31,361 - ridge_corr - INFO - Dropped 0 tiny singular values.. (U is now torch.Size([3200, 3200]))\n",
      "2024-01-27 23:21:31,362 - ridge_corr - INFO - Training stimulus has Frobenius norm: 588.050\n",
      "2024-01-27 23:21:31,436 - ridge_corr - INFO - Training: alpha=1.000, mean corr=0.23708, max corr=0.88424, over-under(0.20)=6498\n",
      "2024-01-27 23:21:31,440 - ridge_corr - INFO - Training: alpha=2.154, mean corr=0.32205, max corr=0.90070, over-under(0.20)=9008\n",
      "2024-01-27 23:21:31,444 - ridge_corr - INFO - Training: alpha=4.642, mean corr=0.43211, max corr=0.91847, over-under(0.20)=10701\n",
      "2024-01-27 23:21:31,448 - ridge_corr - INFO - Training: alpha=10.000, mean corr=0.48078, max corr=0.92184, over-under(0.20)=10954\n",
      "2024-01-27 23:21:31,452 - ridge_corr - INFO - Training: alpha=21.544, mean corr=0.44349, max corr=0.90681, over-under(0.20)=10945\n",
      "2024-01-27 23:21:31,456 - ridge_corr - INFO - Training: alpha=46.416, mean corr=0.34236, max corr=0.86802, over-under(0.20)=10606\n",
      "2024-01-27 23:21:31,460 - ridge_corr - INFO - Training: alpha=100.000, mean corr=0.20986, max corr=0.75890, over-under(0.20)=5382\n",
      "2024-01-27 23:21:31,464 - ridge_corr - INFO - Training: alpha=215.443, mean corr=0.09036, max corr=0.46174, over-under(0.20)=246\n",
      "2024-01-27 23:21:31,469 - ridge_corr - INFO - Training: alpha=464.159, mean corr=0.02819, max corr=0.16830, over-under(0.20)=0\n",
      "2024-01-27 23:21:31,473 - ridge_corr - INFO - Training: alpha=1000.000, mean corr=0.00781, max corr=0.07533, over-under(0.20)=0\n",
      "2024-01-27 23:21:31,474 - counter - INFO - 1/3 items complete (1.42 seconds/item, 00:00:02 remaining)\n",
      "2024-01-27 23:21:31,474 - ridge_corr - INFO - Selecting held-out test set..\n",
      "2024-01-27 23:21:31,478 - ridge_corr - INFO - Doing SVD...\n",
      "2024-01-27 23:21:32,443 - ridge_corr - INFO - Dropped 0 tiny singular values.. (U is now torch.Size([3200, 3200]))\n",
      "2024-01-27 23:21:32,446 - ridge_corr - INFO - Training stimulus has Frobenius norm: 589.129\n",
      "2024-01-27 23:21:32,465 - ridge_corr - INFO - Training: alpha=1.000, mean corr=0.23518, max corr=0.87812, over-under(0.20)=6482\n",
      "2024-01-27 23:21:32,470 - ridge_corr - INFO - Training: alpha=2.154, mean corr=0.32020, max corr=0.89216, over-under(0.20)=8997\n",
      "2024-01-27 23:21:32,474 - ridge_corr - INFO - Training: alpha=4.642, mean corr=0.42985, max corr=0.90768, over-under(0.20)=10695\n",
      "2024-01-27 23:21:32,478 - ridge_corr - INFO - Training: alpha=10.000, mean corr=0.47784, max corr=0.90778, over-under(0.20)=10937\n",
      "2024-01-27 23:21:32,482 - ridge_corr - INFO - Training: alpha=21.544, mean corr=0.44014, max corr=0.88850, over-under(0.20)=10937\n",
      "2024-01-27 23:21:32,485 - ridge_corr - INFO - Training: alpha=46.416, mean corr=0.34012, max corr=0.84478, over-under(0.20)=10587\n",
      "2024-01-27 23:21:32,489 - ridge_corr - INFO - Training: alpha=100.000, mean corr=0.20984, max corr=0.73018, over-under(0.20)=5366\n",
      "2024-01-27 23:21:32,493 - ridge_corr - INFO - Training: alpha=215.443, mean corr=0.09141, max corr=0.44214, over-under(0.20)=254\n",
      "2024-01-27 23:21:32,497 - ridge_corr - INFO - Training: alpha=464.159, mean corr=0.02936, max corr=0.17616, over-under(0.20)=0\n",
      "2024-01-27 23:21:32,501 - ridge_corr - INFO - Training: alpha=1000.000, mean corr=0.00845, max corr=0.09510, over-under(0.20)=0\n",
      "2024-01-27 23:21:32,502 - counter - INFO - 2/3 items complete (1.22 seconds/item, 00:00:01 remaining)\n",
      "2024-01-27 23:21:32,502 - ridge_corr - INFO - Selecting held-out test set..\n",
      "2024-01-27 23:21:32,505 - ridge_corr - INFO - Doing SVD...\n",
      "2024-01-27 23:21:33,469 - ridge_corr - INFO - Dropped 0 tiny singular values.. (U is now torch.Size([3200, 3200]))\n",
      "2024-01-27 23:21:33,470 - ridge_corr - INFO - Training stimulus has Frobenius norm: 588.299\n",
      "2024-01-27 23:21:33,490 - ridge_corr - INFO - Training: alpha=1.000, mean corr=0.23336, max corr=0.89280, over-under(0.20)=6346\n",
      "2024-01-27 23:21:33,494 - ridge_corr - INFO - Training: alpha=2.154, mean corr=0.31969, max corr=0.90523, over-under(0.20)=8927\n",
      "2024-01-27 23:21:33,498 - ridge_corr - INFO - Training: alpha=4.642, mean corr=0.43208, max corr=0.91836, over-under(0.20)=10710\n",
      "2024-01-27 23:21:33,502 - ridge_corr - INFO - Training: alpha=10.000, mean corr=0.48211, max corr=0.91834, over-under(0.20)=10954\n",
      "2024-01-27 23:21:33,506 - ridge_corr - INFO - Training: alpha=21.544, mean corr=0.44517, max corr=0.89342, over-under(0.20)=10958\n",
      "2024-01-27 23:21:33,510 - ridge_corr - INFO - Training: alpha=46.416, mean corr=0.34410, max corr=0.85347, over-under(0.20)=10601\n",
      "2024-01-27 23:21:33,514 - ridge_corr - INFO - Training: alpha=100.000, mean corr=0.21183, max corr=0.74173, over-under(0.20)=5543\n",
      "2024-01-27 23:21:33,518 - ridge_corr - INFO - Training: alpha=215.443, mean corr=0.09197, max corr=0.45580, over-under(0.20)=250\n",
      "2024-01-27 23:21:33,522 - ridge_corr - INFO - Training: alpha=464.159, mean corr=0.02932, max corr=0.19390, over-under(0.20)=0\n",
      "2024-01-27 23:21:33,526 - ridge_corr - INFO - Training: alpha=1000.000, mean corr=0.00835, max corr=0.11840, over-under(0.20)=0\n",
      "2024-01-27 23:21:33,526 - counter - INFO - 3/3 items complete (1.16 seconds/item, 00:00:00 remaining)\n",
      "2024-01-27 23:21:35,441 - ridge_corr - INFO - Total training stimulus has Frobenius norm: 658.328\n",
      "2024-01-27 23:21:35,445 - ridge_corr - INFO - Finding best alpha for each response..\n"
     ]
    }
   ],
   "source": [
    "args2 = copy.deepcopy(args)\n",
    "\n",
    "args.layer = 10\n",
    "args2.layer = 15\n",
    "\n",
    "n_train=4000\n",
    "alphas='adaptive'\n",
    "\n",
    "stim = stim_data['layer_10']\n",
    "resp = stim_data['layer_15']\n",
    "\n",
    "\n",
    "n_total = stim.shape[0]\n",
    "# ids = random.sample(range(n_total), n_train + n_test)\n",
    "\n",
    "\n",
    "tokens = stim_data['context'][:, 5]\n",
    "unique_tokens = []\n",
    "unique_token_ids = []\n",
    "for idx in range(len(tokens)):\n",
    "    if tokens[idx] not in unique_tokens:\n",
    "        unique_tokens.append(tokens[idx])\n",
    "        unique_token_ids.append(idx)\n",
    "random.shuffle(unique_token_ids)\n",
    "ids = unique_token_ids\n",
    "\n",
    "stim = torch.tensor(stim[ids]).cuda().float()\n",
    "resp = torch.tensor(resp[ids]).cuda().float()\n",
    "tstim, hstim = stim[:n_train], stim[n_train:]\n",
    "tresp, hresp = resp[:n_train], resp[n_train:]\n",
    "\n",
    "if alphas is None:\n",
    "    alphas = torch.tensor([1 for _ in range(resp.shape[-1])]).cuda()\n",
    "\n",
    "elif alphas == 'adaptive':\n",
    "    nchunks = int(np.ceil(tresp.shape[0] / 5 / 100))\n",
    "    weights, alphas, bscorrs = bootstrap_ridge_torch(tstim, tresp, use_corr = False, alphas = np.logspace(0, 3, 10),\n",
    "                nboots = 3, chunklen = 100, nchunks = nchunks)        \n",
    "\n",
    "bs_weights = ridge_torch(tstim, tresp, alphas)\n",
    "bs_weights = bs_weights.to(hstim.device).to(hstim.dtype)\n",
    "pred = hstim.matmul(bs_weights)\n",
    "pred = pred.cpu()\n",
    "hresp = hresp.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6414b749-8760-4a4f-88d9-25c87774a10a",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T15:23:39.525250Z",
     "shell.execute_reply.started": "2024-01-27T15:23:28.807563Z",
     "to_execute": "2024-01-27T15:23:28.882Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "neuron_pearson, neuron_p = [], []\n",
    "for i in range(pred.shape[1]):\n",
    "    stat = scipy.stats.pearsonr(pred[:, i].flatten(), hresp[:, i].flatten())\n",
    "    neuron_pearson.append(stat.statistic)\n",
    "    neuron_p.append(stat.pvalue)\n",
    "\n",
    "neuron_pearson = torch.tensor(neuron_pearson)\n",
    "neuron_std = (pred-hresp).std(dim=0)\n",
    "# loss = torch.tensor(stim_data['loss'][ids[n_train:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d797f42e-f24e-4fc1-a3e3-68bcc77410f1",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T15:38:33.843216Z",
     "shell.execute_reply.started": "2024-01-27T15:38:33.260472Z",
     "to_execute": "2024-01-27T15:38:33.243Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "ids_pearson = neuron_pearson.topk(len(neuron_pearson)).indices.tolist()\n",
    "ids_std = neuron_std.topk(len(neuron_pearson)).indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ce1a31a-ca1c-4229-9d65-8867aa55b8bc",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T15:39:11.251920Z",
     "shell.execute_reply.started": "2024-01-27T15:39:11.218223Z",
     "to_execute": "2024-01-27T15:39:11.224Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1742"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1000\n",
    "len(set(ids_pearson[-n:] + ids_std[-n:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "c1472e78-1dee-480e-9ea3-1ca892c1596b",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T09:16:16.333429Z",
     "shell.execute_reply.started": "2024-01-27T09:15:53.606782Z",
     "to_execute": "2024-01-27T09:15:53.489Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "token_pearson, token_p = [], []\n",
    "for i in range(pred.shape[0]):\n",
    "    stat = scipy.stats.pearsonr(pred[i, :].flatten(), hresp[i, :].flatten())\n",
    "    token_pearson.append(stat.statistic)\n",
    "    token_p.append(stat.pvalue)\n",
    "\n",
    "token_pearson = torch.tensor(token_pearson)\n",
    "token_std = (pred-hresp).std(dim=1)\n",
    "loss = torch.tensor(stim_data['loss'][ids[n_train:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c996c3e5-47e4-4859-a172-97760c7b2043",
   "metadata": {
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "38c967e8-fabf-4f89-8684-bbe6a2b62986",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T09:22:08.019493Z",
     "shell.execute_reply.started": "2024-01-27T09:22:07.253598Z",
     "to_execute": "2024-01-27T09:22:07.131Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 PearsonRResult(statistic=0.5115818286841631, pvalue=0.0)\n",
      "1 PearsonRResult(statistic=0.5115818286841631, pvalue=0.0)\n",
      "2 PearsonRResult(statistic=0.5115818286841631, pvalue=0.0)\n",
      "3 PearsonRResult(statistic=0.5115818286841631, pvalue=0.0)\n",
      "4 PearsonRResult(statistic=0.5115818286841631, pvalue=0.0)\n",
      "5 PearsonRResult(statistic=0.5115818286841631, pvalue=0.0)\n",
      "6 PearsonRResult(statistic=0.5115818286841631, pvalue=0.0)\n",
      "7 PearsonRResult(statistic=0.5115818286841631, pvalue=0.0)\n",
      "8 PearsonRResult(statistic=0.5115818286841631, pvalue=0.0)\n",
      "9 PearsonRResult(statistic=0.5115818286841631, pvalue=0.0)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "93b18329-ae00-49e5-9c91-183ddc62732c",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T09:20:59.575960Z",
     "shell.execute_reply.started": "2024-01-27T09:20:59.534945Z",
     "to_execute": "2024-01-27T09:20:59.415Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4956])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hresp.max(dim=1).values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fba74eaf-789f-4f98-b311-e18b2c20c139",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-26T17:21:11.723631Z",
     "shell.execute_reply.started": "2024-01-26T17:21:10.390590Z",
     "to_execute": "2024-01-26T17:21:10.365Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5 500\n",
      "tensor(0.6548, dtype=torch.float64) tensor(0.0770, dtype=torch.float64)\n",
      "tensor(0.6630, dtype=torch.float64) tensor(0.0756, dtype=torch.float64)\n",
      "tensor(0.1743) tensor(0.0201)\n",
      "tensor(0.1762) tensor(0.0217)\n",
      "-4 500\n",
      "tensor(0.6511, dtype=torch.float64) tensor(0.0784, dtype=torch.float64)\n",
      "tensor(0.6628, dtype=torch.float64) tensor(0.0724, dtype=torch.float64)\n",
      "tensor(0.1764) tensor(0.0198)\n",
      "tensor(0.1747) tensor(0.0207)\n",
      "-3 500\n",
      "tensor(0.6570, dtype=torch.float64) tensor(0.0769, dtype=torch.float64)\n",
      "tensor(0.6580, dtype=torch.float64) tensor(0.0777, dtype=torch.float64)\n",
      "tensor(0.1736) tensor(0.0207)\n",
      "tensor(0.1748) tensor(0.0220)\n",
      "-2 500\n",
      "tensor(0.6663, dtype=torch.float64) tensor(0.0787, dtype=torch.float64)\n",
      "tensor(0.6623, dtype=torch.float64) tensor(0.0776, dtype=torch.float64)\n",
      "tensor(0.1716) tensor(0.0241)\n",
      "tensor(0.1749) tensor(0.0220)\n",
      "-1 500\n",
      "tensor(0.6784, dtype=torch.float64) tensor(0.0846, dtype=torch.float64)\n",
      "tensor(0.6575, dtype=torch.float64) tensor(0.0670, dtype=torch.float64)\n",
      "tensor(0.1689) tensor(0.0247)\n",
      "tensor(0.1750) tensor(0.0183)\n",
      "0 500\n",
      "tensor(0.6507, dtype=torch.float64) tensor(0.0706, dtype=torch.float64)\n",
      "tensor(0.6767, dtype=torch.float64) tensor(0.0862, dtype=torch.float64)\n",
      "tensor(0.1771) tensor(0.0202)\n",
      "tensor(0.1738) tensor(0.0233)\n",
      "1 500\n",
      "tensor(0.6418, dtype=torch.float64) tensor(0.0784, dtype=torch.float64)\n",
      "tensor(0.6910, dtype=torch.float64) tensor(0.0635, dtype=torch.float64)\n",
      "tensor(0.1809) tensor(0.0201)\n",
      "tensor(0.1654) tensor(0.0220)\n",
      "2 500\n",
      "tensor(0.6625, dtype=torch.float64) tensor(0.0807, dtype=torch.float64)\n",
      "tensor(0.6947, dtype=torch.float64) tensor(0.0678, dtype=torch.float64)\n",
      "tensor(0.1755) tensor(0.0217)\n",
      "tensor(0.1670) tensor(0.0230)\n",
      "3 500\n",
      "tensor(0.6663, dtype=torch.float64) tensor(0.0771, dtype=torch.float64)\n",
      "tensor(0.6644, dtype=torch.float64) tensor(0.0709, dtype=torch.float64)\n",
      "tensor(0.1736) tensor(0.0221)\n",
      "tensor(0.1771) tensor(0.0187)\n",
      "4 500\n",
      "tensor(0.6667, dtype=torch.float64) tensor(0.0741, dtype=torch.float64)\n",
      "tensor(0.6657, dtype=torch.float64) tensor(0.0733, dtype=torch.float64)\n",
      "tensor(0.1730) tensor(0.0212)\n",
      "tensor(0.1754) tensor(0.0197)\n"
     ]
    }
   ],
   "source": [
    "k = 500\n",
    "\n",
    "pos = -1\n",
    "bias = 5\n",
    "for pos in range(-5, 5):\n",
    "# for k in [100, 200, 300, 400, 500, 1000]:\n",
    "    # sorted_index = loss[:, pos + bias].topk(len(loss)).indices\n",
    "    \n",
    "    test_tokens = stim_data['context'][:, pos + bias][ids[n_train:]]\n",
    "    freq = torch.tensor([counter[i] for i in test_tokens])\n",
    "    sorted_index = freq.topk(len(loss)).indices\n",
    "\n",
    "    current_pearson = token_pearson[sorted_index]\n",
    "    current_std = token_std[sorted_index]\n",
    "    print(pos, k)\n",
    "    print(current_pearson[-k:].mean(), current_pearson[-k:].std())\n",
    "    print(current_pearson[:k].mean(), current_pearson[:k].std())\n",
    "    print(current_std[-k:].mean(), current_std[-k:].std())\n",
    "    print(current_std[:k].mean(), current_std[:k].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f819b1a0-0bda-4f78-81e4-266df5824d27",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T06:19:41.818905Z",
     "shell.execute_reply.started": "2024-01-27T06:19:41.679536Z",
     "to_execute": "2024-01-27T06:19:41.696Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "generate = pipeline('text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "827d3da7-1f52-47c9-b85b-27e4a94cd79d",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T07:43:46.555079Z",
     "shell.execute_reply.started": "2024-01-27T07:35:29.960139Z",
     "to_execute": "2024-01-27T07:35:29.849Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_of_batch = 10\n",
    "n_shot = 1\n",
    "seed = 42\n",
    "dataset = datasets.load_from_disk('/ossfs/workspace/nas/gzhch/data/datasets/alpaca')\n",
    "dataset = dataset.filter(lambda x: x['input'] == '')\n",
    "data = dataset['train'].shuffle(seed=seed).select(range(1000))\n",
    "shots = dataset['train'].shuffle(seed=seed).select(range(1000, 1000 + n_shot))\n",
    "prompt_shots = ''\n",
    "template = 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Response:\\n{output}'\n",
    "\n",
    "for i in range(n_shot):\n",
    "    prompt = template.format(instruction=shots[i]['instruction'], output=shots[i]['output']) + '\\n\\n'\n",
    "    prompt_shots += prompt\n",
    "\n",
    "def process_input(x):\n",
    "    x['text'] = prompt_shots + template.format(instruction=x['instruction'], output='')\n",
    "    x['ground_truth'] = x['output']\n",
    "    return x\n",
    "dataset = data.map(process_input, load_from_cache_file=False)\n",
    "\n",
    "generated_text = generate(dataset[:batch_size * num_of_batch]['text'], return_full_text=False, max_length=300)\n",
    "llm_generated_response = [i[0]['generated_text'].split('\\n\\nBelow is an instruction')[0] for i in generated_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "278f494d-3033-4d07-966d-e54cb97211f7",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T07:45:56.934794Z",
     "shell.execute_reply.started": "2024-01-27T07:45:56.110141Z",
     "to_execute": "2024-01-27T07:45:55.959Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "llm_data = dict(text=[])\n",
    "real_data = dict(text=[])\n",
    "for i in range(batch_size * num_of_batch):\n",
    "    llm_data['text'].append(dataset[i]['text'] + llm_generated_response[i])\n",
    "    real_data['text'].append(dataset[i]['text'] + dataset[i]['output'])\n",
    "\n",
    "with open('/ossfs/workspace/nas/gzhch/data/cache/generated_text/llm_data.pkl', 'wb') as f:\n",
    "    pickle.dump(llm_data, f)\n",
    "with open('/ossfs/workspace/nas/gzhch/data/cache/generated_text/real_data.pkl', 'wb') as f:\n",
    "    pickle.dump(real_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "69eb42cb-f725-429c-ba20-741cdae2c017",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T08:04:33.456338Z",
     "shell.execute_reply.started": "2024-01-27T08:03:44.493657Z",
     "to_execute": "2024-01-27T08:03:44.325Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "acts_llm = llama.get_act(llm_data, \n",
    "                    cache_name = 'alpaca_llm', \n",
    "                    layers = [10, 20],\n",
    "                    acts = {},\n",
    "                    start_batch=0, \n",
    "                    end_batch=10)\n",
    "\n",
    "acts_real = llama.get_act(real_data, \n",
    "                    cache_name = 'alpaca_real', \n",
    "                    layers = [10, 20],\n",
    "                    acts = {},\n",
    "                    start_batch=0, \n",
    "                    end_batch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb2f3ea-42be-49c4-a7f9-d382cb528f91",
   "metadata": {
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "llm_data = dict(text=[])\n",
    "real_data = dict(text=[])\n",
    "for i in range(batch_size * num_of_batch):\n",
    "    llm_data['text'].append(dataset[i]['text'] + llm_generated_response[i])\n",
    "    real_data['text'].append(dataset[i]['text'] + dataset[i]['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ade4f32e-007f-4214-b482-87141452a203",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T08:40:29.018746Z",
     "shell.execute_reply.started": "2024-01-27T08:40:28.452761Z",
     "to_execute": "2024-01-27T08:40:28.297Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "def get_response_mask(full_text, context_text, batch_size=16, num_of_batch=10):\n",
    "    response_masks = []\n",
    "    for k in range(num_of_batch):\n",
    "        full_ids = tokenizer(full_text[k * batch_size: (k + 1) * batch_size], return_tensors='pt', padding='longest')      \n",
    "        context_ids = tokenizer(context_text[k * batch_size: (k + 1) * batch_size], return_tensors='pt', padding='longest')\n",
    "        # response_ids = tokenizer(llm_generated_response[k * batch_size: (k + 1) * batch_size], return_tensors='pt', padding='longest')\n",
    "        response_mask = full_ids['attention_mask'].clone()\n",
    "        response_mask[:, :context_ids['attention_mask'].shape[1]] -= context_ids['attention_mask']\n",
    "        mask = full_ids['attention_mask'][:, :-1] == 1\n",
    "        flattened_response_mask = response_mask[:, :-1].reshape(-1)[mask.flatten()]\n",
    "        response_masks.append(flattened_response_mask)\n",
    "    return torch.cat([i for i in response_masks]) == 1\n",
    "\n",
    "response_mask_llm = get_response_mask(llm_data['text'], dataset['text'])\n",
    "response_mask_real = get_response_mask(real_data['text'], dataset['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "82a07aa0-c41f-4d0c-a549-fcd4d27bd169",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T09:30:21.713373Z",
     "shell.execute_reply.started": "2024-01-27T09:30:21.118542Z",
     "to_execute": "2024-01-27T09:30:21.088Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson 0 PearsonRResult(statistic=0.06551403563608334, pvalue=9.347085065626561e-12)\n",
      "pearson 1 PearsonRResult(statistic=0.07697244672208754, pvalue=1.1317568157066025e-15)\n",
      "pearson 2 PearsonRResult(statistic=0.10583890574131714, pvalue=2.712619446929961e-28)\n",
      "pearson 3 PearsonRResult(statistic=0.12318941915444186, pvalue=8.372109098943815e-38)\n",
      "pearson 4 PearsonRResult(statistic=0.08106732100976202, pvalue=3.194064800904176e-17)\n",
      "pearson 5 PearsonRResult(statistic=0.010039762544111585, pvalue=0.29673461289389774)\n",
      "pearson 6 PearsonRResult(statistic=0.15831647331992302, pvalue=1.392524427804792e-61)\n",
      "pearson 7 PearsonRResult(statistic=0.060394023181881425, pvalue=3.331675162588603e-10)\n",
      "pearson 8 PearsonRResult(statistic=0.045558995154784995, pvalue=2.16458154384645e-06)\n",
      "pearson 9 PearsonRResult(statistic=0.04169222157316585, pvalue=1.4578105040658204e-05)\n",
      "std 0 PearsonRResult(statistic=-0.04771486832816875, pvalue=6.982671457270499e-07)\n",
      "std 1 PearsonRResult(statistic=-0.03389924955492597, pvalue=0.0004248103206017131)\n",
      "std 2 PearsonRResult(statistic=-0.039158497140599595, pvalue=4.674859679846138e-05)\n",
      "std 3 PearsonRResult(statistic=-0.015495133411421343, pvalue=0.10728656373738896)\n",
      "std 4 PearsonRResult(statistic=0.02445452112219685, pvalue=0.011023752845495288)\n",
      "std 5 PearsonRResult(statistic=0.16793755543134303, pvalue=3.582356838248615e-69)\n",
      "std 6 PearsonRResult(statistic=0.05410802163549218, pvalue=1.827516753788112e-08)\n",
      "std 7 PearsonRResult(statistic=0.14130058968742792, pvalue=2.6720099381776297e-49)\n",
      "std 8 PearsonRResult(statistic=0.120438969733462, pvalue=3.372669511318172e-36)\n",
      "std 9 PearsonRResult(statistic=0.09935197147130229, pvalue=4.1286396866183683e-25)\n"
     ]
    }
   ],
   "source": [
    "# counter = Counter(stim_data['context'][:, 5].tolist())\n",
    "for p in range(10):\n",
    "    print('pearson', p, scipy.stats.pearsonr(token_pearson, loss[:, p]))\n",
    "for p in range(10):\n",
    "    print('std', p, scipy.stats.pearsonr(token_std, loss[:, p]))\n",
    "    # print(p, scipy.stats.pearsonr(token_std, hresp.min(dim=1).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "826c18ce-1977-4be6-aa37-3234cd364f8e",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T09:29:36.265827Z",
     "shell.execute_reply.started": "2024-01-27T09:29:36.223529Z",
     "to_execute": "2024-01-27T09:29:36.139Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson 0 PearsonRResult(statistic=0.0590567853392971, pvalue=2.091822601007426e-06)\n",
      "pearson 1 PearsonRResult(statistic=0.07858077007950853, pvalue=2.665693406918057e-10)\n",
      "pearson 2 PearsonRResult(statistic=0.09584027033477563, pvalue=1.2543318046981006e-14)\n",
      "pearson 3 PearsonRResult(statistic=0.13248945004205506, pvalue=1.2437206361811875e-26)\n",
      "pearson 4 PearsonRResult(statistic=0.059881156989395896, pvalue=1.5041071795496062e-06)\n",
      "pearson 5 PearsonRResult(statistic=-0.1579611303390107, pvalue=2.778968534871959e-37)\n",
      "pearson 6 PearsonRResult(statistic=0.22492036164890833, pvalue=1.029773446338501e-74)\n",
      "pearson 7 PearsonRResult(statistic=0.09576699493834981, pvalue=1.3138911626696552e-14)\n",
      "pearson 8 PearsonRResult(statistic=0.06696570288176965, pvalue=7.405045386885828e-08)\n",
      "pearson 9 PearsonRResult(statistic=0.06789642796891635, pvalue=4.86936331867933e-08)\n",
      "std 0 PearsonRResult(statistic=-0.013134732745282256, pvalue=0.29174227643658135)\n",
      "std 1 PearsonRResult(statistic=-0.026369399877877158, pvalue=0.03426724479326846)\n",
      "std 2 PearsonRResult(statistic=-0.022769165906778507, pvalue=0.0675783321870474)\n",
      "std 3 PearsonRResult(statistic=0.00931307507323269, pvalue=0.4547425491206714)\n",
      "std 4 PearsonRResult(statistic=0.08251434045388105, pvalue=3.2594846494081106e-11)\n",
      "std 5 PearsonRResult(statistic=0.16447191699470817, pvalue=2.5766776839545246e-40)\n",
      "std 6 PearsonRResult(statistic=0.0577041093416153, pvalue=3.560866985118755e-06)\n",
      "std 7 PearsonRResult(statistic=0.18003990102584608, pvalue=4.3497207079920675e-48)\n",
      "std 8 PearsonRResult(statistic=0.15902042756389476, pvalue=9.101883745048178e-38)\n",
      "std 9 PearsonRResult(statistic=0.13165265739294305, pvalue=2.583205926995628e-26)\n"
     ]
    }
   ],
   "source": [
    "# counter = Counter(stim_data['context'][:, 5].tolist())\n",
    "for p in range(10):\n",
    "    print('pearson', p, scipy.stats.pearsonr(token_pearson, loss[:, p]))\n",
    "for p in range(10):\n",
    "    print('std', p, scipy.stats.pearsonr(token_std, loss[:, p]))\n",
    "    # print(p, scipy.stats.pearsonr(token_std, hresp.min(dim=1).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "fdb5ea76-6ab9-4745-89d5-ec314ac66985",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T09:25:18.325950Z",
     "shell.execute_reply.started": "2024-01-27T09:24:52.335186Z",
     "to_execute": "2024-01-27T09:24:52.227Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 100\n",
      "tensor(0.5910, dtype=torch.float64) tensor(0.0628, dtype=torch.float64)\n",
      "tensor(0.5251, dtype=torch.float64) tensor(0.1066, dtype=torch.float64)\n",
      "tensor(0.1857) tensor(0.0257)\n",
      "tensor(0.2000) tensor(0.0223)\n",
      "-1 200\n",
      "tensor(0.5782, dtype=torch.float64) tensor(0.0684, dtype=torch.float64)\n",
      "tensor(0.5280, dtype=torch.float64) tensor(0.0968, dtype=torch.float64)\n",
      "tensor(0.1862) tensor(0.0277)\n",
      "tensor(0.2024) tensor(0.0214)\n",
      "-1 300\n",
      "tensor(0.5743, dtype=torch.float64) tensor(0.0704, dtype=torch.float64)\n",
      "tensor(0.5342, dtype=torch.float64) tensor(0.0945, dtype=torch.float64)\n",
      "tensor(0.1871) tensor(0.0258)\n",
      "tensor(0.2027) tensor(0.0210)\n",
      "-1 400\n",
      "tensor(0.5689, dtype=torch.float64) tensor(0.0768, dtype=torch.float64)\n",
      "tensor(0.5380, dtype=torch.float64) tensor(0.0913, dtype=torch.float64)\n",
      "tensor(0.1877) tensor(0.0260)\n",
      "tensor(0.2026) tensor(0.0213)\n",
      "-1 500\n",
      "tensor(0.5647, dtype=torch.float64) tensor(0.0804, dtype=torch.float64)\n",
      "tensor(0.5385, dtype=torch.float64) tensor(0.0910, dtype=torch.float64)\n",
      "tensor(0.1893) tensor(0.0259)\n",
      "tensor(0.2025) tensor(0.0217)\n",
      "-1 1000\n",
      "tensor(0.5513, dtype=torch.float64) tensor(0.0802, dtype=torch.float64)\n",
      "tensor(0.5403, dtype=torch.float64) tensor(0.0872, dtype=torch.float64)\n",
      "tensor(0.1924) tensor(0.0238)\n",
      "tensor(0.2028) tensor(0.0208)\n"
     ]
    }
   ],
   "source": [
    "acts = acts_llm\n",
    "response_mask = response_mask_llm\n",
    "\n",
    "hstim = acts['layer_10'][response_mask]\n",
    "hresp = acts['layer_20'][response_mask]\n",
    "context = acts['context'][response_mask]\n",
    "loss = acts['loss'][response_mask]\n",
    "\n",
    "hstim = torch.tensor(hstim).cuda().float()\n",
    "hresp = torch.tensor(hresp).cuda().float()\n",
    "\n",
    "pred = hstim.matmul(bs_weights)\n",
    "pred = pred.cpu()\n",
    "hresp = hresp.cpu()\n",
    "\n",
    "# scipy.stats.pearsonr(pred.flatten(), hresp.flatten())\n",
    "\n",
    "token_pearson, token_p = [], []\n",
    "for i in range(pred.shape[0]):\n",
    "    stat = scipy.stats.pearsonr(pred[i, :].flatten(), hresp[i, :].flatten())\n",
    "    token_pearson.append(stat.statistic)\n",
    "    token_p.append(stat.pvalue)\n",
    "\n",
    "token_pearson = torch.tensor(token_pearson)\n",
    "token_std = (pred-hresp).std(dim=1)\n",
    "loss = torch.tensor(loss)\n",
    "\n",
    "# k = 500\n",
    "\n",
    "pos = -1\n",
    "bias = 5\n",
    "# for pos in range(-5, 5):\n",
    "for k in [100, 200, 300, 400, 500, 1000]:\n",
    "\n",
    "    sorted_index = loss[:, pos + bias].topk(len(loss)).indices\n",
    "    current_pearson = token_pearson[sorted_index]\n",
    "    current_std = token_std[sorted_index]\n",
    "    print(pos, k)\n",
    "    print(current_pearson[-k:].mean(), current_pearson[-k:].std())\n",
    "    print(current_pearson[:k].mean(), current_pearson[:k].std())\n",
    "    print(current_std[-k:].mean(), current_std[-k:].std())\n",
    "    print(current_std[:k].mean(), current_std[:k].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "9081aa68-68c8-4039-8688-2bd7efcf12b9",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T09:30:21.115728Z",
     "shell.execute_reply.started": "2024-01-27T09:29:39.981287Z",
     "to_execute": "2024-01-27T09:29:39.898Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "tensor(0.5944, dtype=torch.float64) tensor(0.0613, dtype=torch.float64)\n",
      "tensor(0.5626, dtype=torch.float64) tensor(0.0649, dtype=torch.float64)\n",
      "tensor(0.1848) tensor(0.0224)\n",
      "tensor(0.1970) tensor(0.0212)\n",
      "-1\n",
      "tensor(0.5845, dtype=torch.float64) tensor(0.0683, dtype=torch.float64)\n",
      "tensor(0.5634, dtype=torch.float64) tensor(0.0660, dtype=torch.float64)\n",
      "tensor(0.1876) tensor(0.0253)\n",
      "tensor(0.1978) tensor(0.0195)\n",
      "-1\n",
      "tensor(0.5828, dtype=torch.float64) tensor(0.0695, dtype=torch.float64)\n",
      "tensor(0.5587, dtype=torch.float64) tensor(0.0688, dtype=torch.float64)\n",
      "tensor(0.1883) tensor(0.0245)\n",
      "tensor(0.1989) tensor(0.0190)\n",
      "-1\n",
      "tensor(0.5760, dtype=torch.float64) tensor(0.0742, dtype=torch.float64)\n",
      "tensor(0.5548, dtype=torch.float64) tensor(0.0718, dtype=torch.float64)\n",
      "tensor(0.1897) tensor(0.0259)\n",
      "tensor(0.1997) tensor(0.0189)\n",
      "-1\n",
      "tensor(0.5724, dtype=torch.float64) tensor(0.0761, dtype=torch.float64)\n",
      "tensor(0.5526, dtype=torch.float64) tensor(0.0747, dtype=torch.float64)\n",
      "tensor(0.1904) tensor(0.0263)\n",
      "tensor(0.1992) tensor(0.0203)\n",
      "-1\n",
      "tensor(0.5615, dtype=torch.float64) tensor(0.0783, dtype=torch.float64)\n",
      "tensor(0.5524, dtype=torch.float64) tensor(0.0774, dtype=torch.float64)\n",
      "tensor(0.1937) tensor(0.0266)\n",
      "tensor(0.1994) tensor(0.0196)\n"
     ]
    }
   ],
   "source": [
    "acts = acts_real\n",
    "response_mask = response_mask_real\n",
    "\n",
    "hstim = acts['layer_10'][response_mask]\n",
    "hresp = acts['layer_20'][response_mask]\n",
    "context = acts['context'][response_mask]\n",
    "loss = acts['loss'][response_mask]\n",
    "\n",
    "hstim = torch.tensor(hstim).cuda().float()\n",
    "hresp = torch.tensor(hresp).cuda().float()\n",
    "\n",
    "pred = hstim.matmul(bs_weights)\n",
    "pred = pred.cpu()\n",
    "hresp = hresp.cpu()\n",
    "\n",
    "# scipy.stats.pearsonr(pred.flatten(), hresp.flatten())\n",
    "\n",
    "token_pearson, token_p = [], []\n",
    "for i in range(pred.shape[0]):\n",
    "    stat = scipy.stats.pearsonr(pred[i, :].flatten(), hresp[i, :].flatten())\n",
    "    token_pearson.append(stat.statistic)\n",
    "    token_p.append(stat.pvalue)\n",
    "\n",
    "token_pearson = torch.tensor(token_pearson)\n",
    "token_std = (pred-hresp).std(dim=1)\n",
    "loss = torch.tensor(loss)\n",
    "\n",
    "# k = 500\n",
    "\n",
    "pos = -1\n",
    "bias = 5\n",
    "# for pos in range(-5, 5):\n",
    "for k in [100, 200, 300, 400, 500, 1000]:\n",
    "\n",
    "    sorted_index = loss[:, pos + bias].topk(len(loss)).indices\n",
    "    current_pearson = token_pearson[sorted_index]\n",
    "    current_std = token_std[sorted_index]\n",
    "    print(pos)\n",
    "    print(current_pearson[-k:].mean(), current_pearson[-k:].std())\n",
    "    print(current_pearson[:k].mean(), current_pearson[:k].std())\n",
    "    print(current_std[-k:].mean(), current_std[-k:].std())\n",
    "    print(current_std[:k].mean(), current_std[:k].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "b5882855-139d-4bff-961f-531198ae059a",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T09:13:36.899567Z",
     "shell.execute_reply.started": "2024-01-27T09:13:36.392506Z",
     "to_execute": "2024-01-27T09:13:36.270Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10804])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_pearson.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "cbf3910d-8f4f-40cc-b5d6-2f94ae6715ab",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T09:14:05.711905Z",
     "shell.execute_reply.started": "2024-01-27T09:14:05.682880Z",
     "to_execute": "2024-01-27T09:14:05.562Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.07745112391114177, pvalue=7.528566521747938e-16)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.pearsonr(token_pearson, loss[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "043f5922-33d5-4945-ac61-92e4e8980c56",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2024-01-27T09:14:54.024217Z",
     "shell.execute_reply.started": "2024-01-27T09:14:53.988127Z",
     "to_execute": "2024-01-27T09:14:53.865Z"
    },
    "libroFormatter": "formatter-string"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PearsonRResult(statistic=-0.045255122939267485, pvalue=2.5288748735423885e-06)\n",
      "PearsonRResult(statistic=-0.0347857845087261, pvalue=0.0002987399432932972)\n",
      "PearsonRResult(statistic=-0.04060932964580527, pvalue=2.4184340390061123e-05)\n",
      "PearsonRResult(statistic=-0.018479285124304967, pvalue=0.054766891419967156)\n",
      "PearsonRResult(statistic=0.025392642163795588, pvalue=0.00830309726029765)\n",
      "PearsonRResult(statistic=0.1754278043680453, pvalue=2.0861027495329813e-75)\n",
      "PearsonRResult(statistic=0.04434820326008646, pvalue=3.99986801400221e-06)\n",
      "PearsonRResult(statistic=0.1365000865910419, pvalue=4.27908452819686e-46)\n",
      "PearsonRResult(statistic=0.11610285766890506, pvalue=9.6311219996744e-34)\n",
      "PearsonRResult(statistic=0.09559757894579464, pvalue=2.3200777451621803e-23)\n"
     ]
    }
   ],
   "source": [
    "for p in range(10):\n",
    "    print(scipy.stats.pearsonr(token_std, loss[:, p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f4e50d-8657-412e-b644-e5b11f364be8",
   "metadata": {
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
